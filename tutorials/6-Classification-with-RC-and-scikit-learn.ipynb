{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook performs classification on the Japanese Vowel dataset, similar to Notebook 5. However, instead of using reservoir.py's native Ridge Readout, we use scikit learn's Ridge linear regression model. We have created a new node called RidgeRegression which is compatible with all the nodes in reservoir.py. Thus, we can easily create models following the link operations. The only caveat while using scikit-learn's RidgeRegression or LinearRegression node is to have the input data and output labels as 2D matrices. This is because unlike reservoir.py's readout nodes, scikit-learn nodes do not have an option for performing partial fit. Their Linear Regression estimators fit the data at one go. Thus if you want to fit data which is in the format of [num_sequences, time series, features], you will first have to convert the data into a format such that it is [num_sequences, time series * features]. Similarly, target labels also need to be either 1-d or 2d array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pdb\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from reservoirpy.datasets import japanese_vowels\n",
    "from reservoirpy import set_seed, verbosity\n",
    "from reservoirpy.observables import nrmse, rsquare\n",
    "from reservoirpy.nodes import Reservoir, RidgeRegression, Input, ElasticNet, Lasso\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "set_seed(42)\n",
    "verbosity(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = japanese_vowels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = Input()\n",
    "reservoir = Reservoir(500, sr=0.9, lr=0.1)\n",
    "readout = ElasticNet(alpha=0.001)\n",
    "model = source >> reservoir >> readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deep/opt/miniconda3/envs/pytorch2/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0833273442553355, tolerance: 0.0026666666666666666\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/deep/opt/miniconda3/envs/pytorch2/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.059622463673296267, tolerance: 0.0026666666666666666\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/deep/opt/miniconda3/envs/pytorch2/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.024065111105481485, tolerance: 0.0026666666666666666\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/deep/opt/miniconda3/envs/pytorch2/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.030939108739096888, tolerance: 0.0026666666666666657\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/deep/opt/miniconda3/envs/pytorch2/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03717589033084323, tolerance: 0.0026666666666666657\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/deep/opt/miniconda3/envs/pytorch2/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.073474773840573, tolerance: 0.0026666666666666657\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/deep/opt/miniconda3/envs/pytorch2/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013890741377173832, tolerance: 0.0026666666666666666\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ElasticNet-0': ElasticNet(f=<function elastic_net at 0x7fcfb9295430>, in=500, out=9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_train = []\n",
    "for x in X_train:\n",
    "    states = reservoir.run(x, reset=True)\n",
    "    states_train.append(states[-1, np.newaxis])\n",
    "\n",
    "# the ridge regression class expects inputs and outputs as a numpy 2d matrix\n",
    "# thus we do a bit of pre-processing where we convert the states_train list \n",
    "# and Y_train into a numpy array and remove any unecessary dimensions\n",
    "readout.fit(np.array(states_train).squeeze(), np.array(Y_train).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_test = []\n",
    "for x in X_test:\n",
    "    states = reservoir.run(x, reset=True)\n",
    "    states_test.append(states[-1, np.newaxis])\n",
    "y_pred = readout.run(np.array(states_test).squeeze())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  98.108 %\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.array(Y_test).squeeze()\n",
    "Y_pred_class = np.argmax(y_pred, axis=1)\n",
    "Y_test_class = np.argmax(Y_test, axis=1)\n",
    "score = accuracy_score(Y_test_class, Y_pred_class)\n",
    "\n",
    "print(\"Accuracy: \", f\"{score * 100:.3f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
