{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Reservoir Computing with ReservoirPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from reservoirpy import mat_gen, ESN\n",
    "\n",
    "# just a little tweak to center the plots, nothing to worry about\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mackey-Glass timeserie\n",
    "\n",
    "Mackey-Glass equation are a set of delayed differential equations describing the temporal behaviour of different physiological signal, for example, the relative quantity of mature blood cells over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The equations are defined as:\n",
    "\n",
    "$$\n",
    "\\frac{dP(t)}{dt} = \\frac{a P(t - \\tau)}{1 + P(t - \\tau)^n} - bP(t)\n",
    "$$\n",
    "\n",
    "where $a = 0.2$, $b = 0.1$, $n = 10$, and the time delay $\\tau = 17$. $\\tau$ controls the chaotic behaviour of the equations (the higher it is, the more chaotic the timeserie becomes. $\\tau=17$ already gives good chaotic results.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from reservoirpy.datasets.chaos import mackey_glass\n",
    "\n",
    "timesteps = 25000\n",
    "tau = 17\n",
    "X, t = mackey_glass(timesteps, tau=tau)\n",
    "\n",
    "# rescale between -1 and 1\n",
    "X = 2 * (X - X.min()) / (X.max() - X.min()) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_mackey_glass(X, t, sample, tau):\n",
    "\n",
    "    fig = plt.figure(figsize=(13, 5))\n",
    "\n",
    "    plt.subplot((121))\n",
    "    plt.title(f\"Timeserie - {sample} timesteps\")\n",
    "    plt.plot(t[:sample], X[:sample], lw=2, \n",
    "             color=\"lightgrey\", zorder=0)\n",
    "    plt.scatter(t[:sample], X[:sample], c=t[:sample], cmap=\"viridis\", s=6)\n",
    "    plt.xlabel(\"$t$\")\n",
    "    plt.ylabel(\"$P(t)$\")\n",
    "\n",
    "    ax = plt.subplot((122))\n",
    "    ax.margins(0.05)\n",
    "    plt.title(f\"Phase diagram: $P(t) = f(P(t-\\\\tau))$\")\n",
    "    plt.plot(X[0: sample], X[tau: sample+tau], lw=1, \n",
    "             color=\"lightgrey\", zorder=0)\n",
    "    plt.scatter(X[:sample], X[tau: sample+tau], \n",
    "             lw=0.5, c=t[:sample], cmap=\"viridis\", s=6)\n",
    "    plt.xlabel(\"$P(t-\\\\tau)$\")\n",
    "    plt.ylabel(\"$P(t)$\")\n",
    "    \n",
    "    cbar = plt.colorbar()\n",
    "    cbar.ax.set_ylabel('$t$', rotation=270)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_mackey_glass(X, t, 500, tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prepare the tasks\n",
    "\n",
    "- Task 1: prediction of the timeserie: from $P(t)$ predict $P(t + 1)$, $P(t + 10)$ (the forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Task 2: generation of the timeserie (from $P$ generate $\\hat{P}$, and run it over several timesteps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def split_timeserie_for_task1(forecast, train_length=20000):\n",
    "\n",
    "    X_train, y_train = X[:train_length], X[forecast: train_length+forecast]\n",
    "    X_test, y_test = X[train_length: -forecast], X[train_length+forecast:]\n",
    "    \n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Task 1 : prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "forecast = 10  # for now, predict 10 steps ahead\n",
    "(X_train, y_train), (X_test, y_test) = split_timeserie_for_task1(forecast)\n",
    "\n",
    "sample = 500\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "plt.plot(X_train[:sample], label=\"Training data\")\n",
    "plt.plot(y_train[:sample], label=\"True prediction\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Task 1: prepare the ESN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "units = 100\n",
    "leak_rate = 0.3\n",
    "spectral_radius = 1.25\n",
    "input_scaling = 1.0\n",
    "density = 0.1\n",
    "input_connectivity = 0.2\n",
    "regularization = 1e-8\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def reset_esn():\n",
    "    Win = mat_gen.generate_input_weights(units, 1, input_scaling=input_scaling, \n",
    "                                     proba=input_connectivity, input_bias=True,\n",
    "                                     seed=seed)\n",
    "\n",
    "    W = mat_gen.generate_internal_weights(units, spectral_radius=spectral_radius,\n",
    "                                  proba=density, seed=seed)\n",
    "\n",
    "    reservoir = ESN(leak_rate, W, Win, ridge=regularization)\n",
    "    \n",
    "    return reservoir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "im = plt.imread(\"./static/esn.png\")\n",
    "plt.figure(figsize=(15, 15)); plt.imshow(im); plt.axis('off'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "Win = mat_gen.generate_input_weights(units, 1, input_scaling=input_scaling, \n",
    "                                     proba=input_connectivity, input_bias=True,\n",
    "                                     seed=seed)\n",
    "\n",
    "W = mat_gen.generate_internal_weights(units, spectral_radius=spectral_radius,\n",
    "                              proba=density, seed=seed)\n",
    "\n",
    "reservoir = ESN(leak_rate, W, Win, ridge=regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Task 1: train and test the ESN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "states = reservoir.train([X_train.reshape(-1, 1)], [y_train.reshape(-1, 1)], verbose=True)\n",
    "\n",
    "y_pred, states1 = reservoir.run([X_test.reshape(-1, 1)], init_state=states[0][-1], verbose=True)\n",
    "\n",
    "y_pred = y_pred[0].flatten()\n",
    "states1 = states1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def r2_score(y_true, y_pred):\n",
    "    return 1 - (np.sum((y_true - y_pred)**2) / np.sum((y_true - y_true.mean())**2))\n",
    "\n",
    "def nrmse(y_true, y_pred):\n",
    "    return np.sqrt((np.sum(y_true - y_pred)**2) / len(y_true)) / (y_true.max() - y_true.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sample = 500\n",
    "\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.plot(np.arange(sample), y_pred[:sample], lw=3, label=\"ESN prediction\")\n",
    "plt.plot(np.arange(sample), y_test[:sample], linestyle=\"--\", lw=2, label=\"True value\")\n",
    "plt.plot(np.abs(y_test[:sample] - y_pred[:sample]), label=\"Absolute deviation\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Determination coefficient $R^2$ and normalized root mean square (NRMSE) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "r2_score(y_test, y_pred), nrmse(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Task 1 : make the task harder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "forecast = 50  # now, predict 50 steps ahead\n",
    "(X_train, y_train), (X_test, y_test) = split_timeserie_for_task1(forecast)\n",
    "\n",
    "sample = 500\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "plt.plot(X_train[:sample], label=\"Training data\")\n",
    "plt.plot(y_train[:sample], label=\"True prediction\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "states = reservoir.train([X_train.reshape(-1, 1)], [y_train.reshape(-1, 1)], verbose=True)\n",
    "\n",
    "y_pred, states2 = reservoir.run([X_test.reshape(-1, 1)], init_state=states[0][-1], verbose=True)\n",
    "\n",
    "y_pred = y_pred[0].flatten()\n",
    "states2 = states2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sample = 500\n",
    "\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.plot(np.arange(sample), y_pred[:sample], lw=3, label=\"ESN prediction\")\n",
    "plt.plot(np.arange(sample), y_test[:sample], linestyle=\"--\", lw=2, label=\"True value\")\n",
    "plt.plot(np.abs(y_test[:sample] - y_pred[:sample]), label=\"Absolute deviation\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Determination coefficient $R^2$ and NRMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "r2_score(y_test, y_pred), nrmse(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Task 1 : diving into the reservoir\n",
    "\n",
    "Let's have a look at the effect of some of the hyperparameters of the ESN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Spectral radius\n",
    "\n",
    "\n",
    "The spectral radius is defined as the maximum eigenvalue of the reservoir matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "reservoir = reset_esn()\n",
    "\n",
    "states = []\n",
    "radii = [0.1, 1.25, 10.0]\n",
    "for sr in radii:\n",
    "    W = mat_gen.generate_internal_weights(units, spectral_radius=sr, \n",
    "                                          proba=density, seed=seed)\n",
    "    reservoir.W = W\n",
    "    s = reservoir.compute_all_states([X_test[:500].reshape(-1, 1)])\n",
    "    states.append(s[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "units_nb = 20\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i, s in enumerate(states):\n",
    "    plt.subplot(len(radii)*100+10+i+1)\n",
    "    plt.plot(s[:, :units_nb] + 2*i)\n",
    "    plt.ylabel(f\"$sr={radii[i]}$\")\n",
    "plt.xlabel(f\"States ({units_nb} neurons)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- $-$ spectral radius $\\rightarrow$ **stable** dynamics\n",
    "\n",
    "- $+$ spectral radius $\\rightarrow$ **chaotic** dynamics\n",
    "\n",
    "In most cases, it should have a value around $1.0$ to ensure the *echo state property* (ESP): the dynamics of the reservoir should not be bound to the initial state chosen, and remains close to chaos. \n",
    "\n",
    "This value also heavily depends on the input scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Input scaling\n",
    "\n",
    "The input scaling controls how the ESN interact with the inputs. It is a coefficient appliyed to the input matrix $W_{in}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "reservoir = reset_esn()\n",
    "\n",
    "states = []\n",
    "scalings = [0.1, 1.0, 10.0]\n",
    "for iss in scalings:\n",
    "    Win = mat_gen.generate_input_weights(units, 1, input_scaling=iss,\n",
    "                                     proba=input_connectivity, input_bias=True,\n",
    "                                     seed=seed)\n",
    "    reservoir.Win = Win\n",
    "    s = reservoir.compute_all_states([X_test[:500].reshape(-1, 1)])\n",
    "    states.append(s[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "units_nb = 20\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i, s in enumerate(states):\n",
    "    plt.subplot(len(scalings)*100+10+i+1)\n",
    "    plt.plot(s[:, :units_nb] + 2*i)\n",
    "    plt.ylabel(f\"$iss={scalings[i]}$\")\n",
    "plt.xlabel(f\"States ({units_nb} neurons)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- $+$ input scaling $\\rightarrow$ **input-driven** activities\n",
    "- $-$ input scaling $\\rightarrow$ **free** activities\n",
    "\n",
    "The input scaling can also be used to rescale the inputs and ajust their influences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Leaking rate\n",
    "\n",
    "The leaking rate ($\\alpha$) controls the \"memory feedback\" of the ESN. The ESN states are indeed computed as:\n",
    "\n",
    "$$ \n",
    "s(t+1) =  \\underbrace{\\color{red}{(1 - \\alpha)} s(t)}_{\\text{previous states}} + \\underbrace{\\color{red}\\alpha f(u(t+1), s(t))}_{\\text{new states}}\n",
    "$$\n",
    "\n",
    "where $s$ is the state, $u$ is the input data, $f$ is the ESN model function, defined as:\n",
    "\n",
    "$$ f(u, s) = \\tanh(W_{in} \\cdotp u + W \\cdotp s) $$\n",
    "\n",
    "$\\alpha$ must be in $[0; 1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "reservoir = reset_esn()\n",
    "\n",
    "states = []\n",
    "rates = [0.03, 0.3, 0.99]\n",
    "for lr in rates:\n",
    "    reservoir.lr = lr\n",
    "    s = reservoir.compute_all_states([X_test[:500].reshape(-1, 1)])\n",
    "    states.append(s[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "units_nb = 20\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i, s in enumerate(states):\n",
    "    plt.subplot(len(rates)*100+10+i+1)\n",
    "    plt.plot(s[:, :units_nb] + 2*i)\n",
    "    plt.ylabel(f\"$lr={rates[i]}$\")\n",
    "plt.xlabel(f\"States ({units_nb} neurons)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "reservoir = reset_esn()\n",
    "\n",
    "Win = mat_gen.generate_input_weights(units, 1, input_scaling=0.1, input_bias=True)\n",
    "reservoir.Win = Win\n",
    "\n",
    "states = []\n",
    "rates = [0.03, 0.3, 0.9]\n",
    "for lr in rates:\n",
    "    reservoir.lr = lr\n",
    "    s = reservoir.compute_all_states([X_test[:500].reshape(-1, 1)])\n",
    "    states.append(s[0].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's reduce the input influence to see what is happening inside the reservoir (input scaling set to $0.1$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "units_nb = 20\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i, s in enumerate(states):\n",
    "    plt.subplot(len(rates)*100+10+i+1); plt.ylabel(f\"$lr={rates[i]}$\")\n",
    "    plt.plot(s[:, :units_nb] + 2*i)\n",
    "plt.xlabel(f\"States ({units_nb} neurons)\"); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- $+$ leaking rate $\\rightarrow$ **low inertia**, little memory of previous states\n",
    "- $-$ leaking rate $\\rightarrow$ **high inertia**, big memory of previous states\n",
    "\n",
    "The leaking rate can be seen as the inverse of the reservoir's time contant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Task 2 : generate predictions\n",
    "\n",
    "During this task, the ESN is trained to make a short forecast of the timeserie (1 timestep ahead).\n",
    "Then, it will be asked to run on its own outputs, trying to predict its own behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "units = 500\n",
    "leak_rate = 0.15\n",
    "spectral_radius = 0.48\n",
    "input_scaling = 1.0\n",
    "density = 0.1\n",
    "input_connectivity = 1.0\n",
    "regularization = 1e-6\n",
    "seed = 1234\n",
    "\n",
    "reservoir = reset_esn()\n",
    "\n",
    "forecast = 1\n",
    "(X_train, y_train), (X_test, y_test) = split_timeserie_for_task1(forecast)\n",
    "\n",
    "states = reservoir.train([X_train.reshape(-1, 1)], [y_train.reshape(-1, 1)], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_generation(X_gen, X_t, init_inputs, nb_generations, seed_timesteps):\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(X_gen, label=\"Generated timeserie\")\n",
    "    plt.plot(np.arange(nb_generations)+seed_timesteps, X_t, linestyle=\"--\", label=\"Real timeserie\")\n",
    "    plt.plot(np.arange(seed_timesteps), init_inputs, linestyle=\"--\", label=\"Init inputs\")\n",
    "    plt.plot(np.arange(nb_generations)+seed_timesteps, np.abs(X_t - X_gen[seed_timesteps:]), \n",
    "             label=\"Absolute deviation\")\n",
    "    plt.fill_between([0, seed_timesteps], *plt.ylim(), facecolor='lightgray', alpha=0.5, label=\"Seed\")\n",
    "\n",
    "    plt.plot([], [], ' ', label=f\"$R^2 = {round(r2_score(X_t, X_gen[seed_timesteps:]), 4)}$\")\n",
    "    plt.plot([], [], ' ', label=f\"$NRMSE = {round(nrmse(X_t, X_gen[seed_timesteps:]), 4)}$\")\n",
    "    plt.legend(\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "start = 0; seed_timesteps = 100; nb_generations = 500\n",
    "\n",
    "init_inputs = X_test[start:start+seed_timesteps]\n",
    "X_t = X_test[start+seed_timesteps: start+nb_generations+seed_timesteps]\n",
    "\n",
    "X_gen, states = reservoir.generate(nb_generations, init_inputs.reshape(-1, 1), return_init=True)\n",
    "X_gen = X_gen.flatten()\n",
    "\n",
    "plot_generation(X_gen, X_t, init_inputs, nb_generations, seed_timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Another example: generate Lorenz butterflies\n",
    "\n",
    "Lorenz attractor is another well-known example of chaotic timeserie generator. \n",
    "\n",
    "Here, the ESN has to predict 3 covariant values at once: the $x$, $y$ and $z$ coordinates of the Lorenz system. \n",
    "\n",
    "\n",
    "We can also ask the ESN to predict one value given the two others, and so on. Of course, we can also ask for new generations of the timeserie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from reservoirpy.datasets.chaos import lorenz\n",
    "\n",
    "timesteps = 25000\n",
    "X, t = lorenz(timesteps)\n",
    "\n",
    "# rescale between -1 and 1\n",
    "X = 2 * (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_lorenz(X, t, sample):\n",
    "    \n",
    "    x, y, z = X[:, 0], X[:, 1], X[:, 2]\n",
    "    fig = plt.figure(figsize=(13, 5))\n",
    "\n",
    "    plt.subplot((121))\n",
    "    plt.title(f\"Timeserie - {sample} timesteps\")\n",
    "    \n",
    "    plt.plot(t[:sample], x[:sample], color=\"lightgray\", zorder=0)\n",
    "    plt.scatter(t[:sample], x[:sample], c=t[:sample], cmap=\"viridis\", s=2, zorder=1)\n",
    "    \n",
    "    plt.xlabel(\"$t$\")\n",
    "    plt.ylabel(\"$x$\")\n",
    "    \n",
    "    cbar = plt.colorbar()\n",
    "    cbar.ax.set_ylabel('$t$', rotation=270)\n",
    "\n",
    "    ax = plt.subplot((122), projection=\"3d\")\n",
    "    ax.margins(0.05)\n",
    "    plt.title(f\"Phase diagram: $z = f(x)$\")\n",
    "    plt.plot(x[:sample], y[:sample], z[:sample], lw=1, \n",
    "             color=\"lightgrey\", zorder=0)\n",
    "    plt.scatter(x[:sample], y[:sample], zs=z[:sample],\n",
    "             lw=0.5, c=t[:sample], cmap=\"viridis\", s=2)\n",
    "    plt.xlabel(\"$x$\")\n",
    "    plt.ylabel(\"$y$\")\n",
    "    ax.set_zlabel(\"$z$\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_lorenz(X, t, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "units = 500\n",
    "leak_rate = 0.2\n",
    "spectral_radius = 1.0\n",
    "input_scaling = 1.\n",
    "density = 0.1\n",
    "input_connectivity = 1.0\n",
    "regularization = 1e-6\n",
    "seed = 1234\n",
    "\n",
    "Win = mat_gen.generate_input_weights(units, 3, input_scaling=input_scaling, \n",
    "                                     proba=input_connectivity, input_bias=True,\n",
    "                                     seed=seed)\n",
    "\n",
    "W = mat_gen.generate_internal_weights(units, spectral_radius=spectral_radius,\n",
    "                              proba=density, seed=seed)\n",
    "\n",
    "reservoir = ESN(leak_rate, W, Win, ridge=regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "forecast = 1\n",
    "(X_train, y_train), (X_test, y_test) = split_timeserie_for_task1(forecast)\n",
    "\n",
    "states = reservoir.train([X_train], [y_train], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "start = 0; seed_timesteps = 100; nb_generations = 500\n",
    "\n",
    "init_inputs = X_test[start:start+seed_timesteps]\n",
    "X_t = X_test[start+seed_timesteps: start+nb_generations+seed_timesteps]\n",
    "\n",
    "X_gen, states = reservoir.generate(nb_generations, init_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 20))\n",
    "plt.subplot(211, projection=\"3d\")\n",
    "plt.plot(X_gen[:, 0], X_gen[:, 1], X_gen[:, 2], lw=3, label=\"ESN prediction\")\n",
    "plt.plot(X_t[:, 0], X_t[:, 1], X_t[:, 2], linestyle=\"--\", lw=2, label=\"True value\")\n",
    "plt.plot([], [], ' ', label=f\"$R^2 = {round(r2_score(X_t, X_gen), 4)}$\")\n",
    "plt.plot([], [], ' ', label=f\"$NRMSE = {round(nrmse(X_t, X_gen), 4)}$\")\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Not as easy as Mackey-Glass..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "More fun with ReservoirPy and chaotic data: multiscroll attractor, Rabinovich-Fabrikant equations, Hénon map... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from reservoirpy.datasets.chaos import multiscroll, rabinovich_fabrikant, henon_map\n",
    "\n",
    "def plot_attractor_examples():\n",
    "    \n",
    "    Xm, tm = multiscroll(1000)\n",
    "    Xr, tr = rabinovich_fabrikant(1000)\n",
    "    Xh = henon_map(100)\n",
    "    \n",
    "    plt.figure(figsize=(20, 5))\n",
    "\n",
    "    plt.subplot(141)\n",
    "    plt.margins(0.05)\n",
    "    plt.plot(Xm[:, 0], Xm[:, 2], color=\"lightgray\", zorder=0)\n",
    "    plt.scatter(Xm[:, 0], Xm[:, 2], cmap=\"viridis\", c=tm, s=6)\n",
    "    plt.title(\"Multiscroll attractor\")\n",
    "\n",
    "    plt.subplot(142)\n",
    "    plt.margins(0.05)\n",
    "    plt.plot(Xr[:, 0], Xr[:, 2], color=\"lightgray\", zorder=0)\n",
    "    plt.scatter(Xr[:, 0], Xr[:, 2], cmap=\"viridis\", c=tm, s=6)\n",
    "    plt.title(\"Rabinovich-Fabrikant system\")\n",
    "\n",
    "    plt.subplot(143)\n",
    "    plt.margins(0.05)\n",
    "    plt.plot(Xh[:, 0], Xh[:, 1], color=\"lightgray\", zorder=0, lw=1)\n",
    "    plt.scatter(Xh[:, 0], Xh[:, 1], cmap=\"viridis\", c=range(len(Xh)), s=10)\n",
    "    plt.title(\"Hénon map\")\n",
    "    \n",
    "    plt.subplot(144)\n",
    "    im = plt.imread(\"static/more_chaos.png\")\n",
    "    plt.imshow(im)\n",
    "    plt.title(\"And more chaos to come soon !\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plot_attractor_examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Now the *pièce de resistance*: real data from the real world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# uncomment the following line to install the required packages I forgot to tell you about... \n",
    "# (leave the '!' in place, it's important)\n",
    "# if it doesn't work, try using pip and a terminal, or Anaconda. We need 'pandas' and 'requests'.\n",
    "\n",
    "#!pip install requests pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "data = requests.get(\"https://www.data.gouv.fr/fr/datasets/r/d2671c6c-c0eb-4e12-b69a-8e8f87fc224c\").json()\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "French Covid-19 data is available at www.data.gouv.fr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A new task for the braves : predict the number of hospitalized people\n",
    "\n",
    "We selected 4 interesting features: the number of people hospitalized and new hospitalizations per day, and the number of people in intensive care (*réanimation*) and new admissions in intensive care per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df = df.fillna(0)  # don't forget to remove NaN...\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"]) \n",
    "df = df.sort_values(by=\"date\").reset_index(drop=True) # ...and to sort the data by increasing time (I forgot to do\n",
    "                                                      # that the first time and it was obviously horrible)\n",
    "\n",
    "feat_names = ['reanimation', 'hospitalises',  # hostpitalizations features names\n",
    "              'nouvellesHospitalisations', 'nouvellesReanimations']  # intensive care features names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_dataframe(features, df):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, feat in enumerate(feat_names):\n",
    "        plt.plot(df[feat], label=feat)\n",
    "    ticks = [0, 50, 100, 150, 200, 250]\n",
    "    plt.xticks(ticks, [df[\"date\"].loc[i].date() for i in ticks], rotation=45)\n",
    "    plt.ylabel(\"Reported COVID deaths\")\n",
    "    plt.legend(); plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plot_dataframe(feat_names, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Prepare the data\n",
    "\n",
    "We apply a 5 days mean with a Hamming window on each curve, to reduce noise. We also rescale the data between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "X_roll = np.array([df[f].rolling(5, win_type=\"hamming\").mean().fillna(0).values for f in feat_names]).T\n",
    "X = (X_roll - X_roll.min(axis=0)) / (X_roll.max(axis=0) - X_roll.min(axis=0))\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, feat in enumerate(feat_names):\n",
    "    plt.plot(X[:, i], label=feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "forecast = 1\n",
    "start = 20\n",
    "train_length = 230\n",
    "\n",
    "x_train = X[start: train_length]\n",
    "y_train = X[start+forecast: train_length+forecast]\n",
    "\n",
    "x_test = X[train_length: -forecast]\n",
    "y_test = X[train_length+forecast:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Train the ESN\n",
    "\n",
    "Because we have 4 different inputs, we can decide to apply 4 different inputs scalings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "units = 1000\n",
    "leak_rate = 0.5\n",
    "spectral_radius = 0.9\n",
    "inputs_scalings = [1.0, 1.0, 1.0, 1.0] # 4 input scalings, one per feature\n",
    "density = 0.2\n",
    "input_connectivity = 0.2\n",
    "regularization = 1e-5\n",
    "seed = 1234\n",
    "\n",
    "Wins = []\n",
    "bias = True\n",
    "for iss in inputs_scalings:\n",
    "    Win = mat_gen.generate_input_weights(units, 1, input_scaling=iss, \n",
    "                                         proba=input_connectivity, input_bias=bias,\n",
    "                                         seed=seed)\n",
    "    bias = False  # bias added only once !\n",
    "    Wins.append(Win)\n",
    "\n",
    "Win = np.hstack(Wins)  # 4 input matrices, one per feature, merged into one\n",
    "\n",
    "\n",
    "W = mat_gen.fast_spectral_initialization(units, spectral_radius=spectral_radius,\n",
    "                              proba=density, seed=seed)\n",
    "\n",
    "reservoir = ESN(leak_rate, W, Win, ridge=regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "states = reservoir.train([x_train], [y_train], verbose=True, wash_nr_time_step=0)\n",
    "\n",
    "y_pred, states = reservoir.generate(x_test.shape[0], init_inputs=x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_bofbof_results(activate_meme=False):\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    color = matplotlib.rcParams['axes.prop_cycle'][:len(feat_names)]\n",
    "    \n",
    "    if activate_meme:\n",
    "        gs = matplotlib.gridspec.GridSpec(1, 2, width_ratios=[3, 2])\n",
    "        ax2 = fig.add_subplot(gs[1])\n",
    "        im = plt.imread(\"static/confused_financial_guy.png\")\n",
    "        ax2.imshow(im)\n",
    "    else:\n",
    "        gs = matplotlib.gridspec.GridSpec(1, 1)\n",
    "\n",
    "    ax1 = fig.add_subplot(gs[0])\n",
    "    ax1.set_prop_cycle(color)\n",
    "    ax1.set_title(f\"{len(y_test)} days forecast of Covid hospitalization indicators\")\n",
    "    ax1.plot(y_pred)\n",
    "    ax1.plot(y_test, linestyle=\"--\")\n",
    "    ax1.plot([],[], color=\"black\", label=\"Generated\")\n",
    "    ax1.plot([],[], linestyle=\"--\", color=\"black\", label=\"Real\")\n",
    "    ax1.plot([],[],' ', label=f\"$R^2={round(r2_score(y_test, y_pred), 4)}$\")\n",
    "    ax1.plot([],[],' ', label=f\"$NRMSE={round(nrmse(y_test, y_pred), 4)}$\")\n",
    "    ax1.set_ylabel(\"Normalized indicator\")\n",
    "    ticks = [i for i in range(0, len(y_test), 5)]\n",
    "    ax1.set_xticks(ticks)\n",
    "    ax1.set_xticklabels([df[\"date\"].loc[len(y_train) + i].date() for i in ticks], rotation=45)\n",
    "    ax1.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_bofbof_results(activate_meme=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What you could try then:\n",
    "\n",
    "- Playing with the parameters\n",
    "- Some feature engineering and \"old school\" data science\n",
    "- Hyperopt and ReservoirPy hyperoptimization tools\n",
    "- Add some feedback\n",
    "- Try ensembling methods with several estimators\n",
    "- Contact French government when you are done (and save the world)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('venv': venv)",
   "language": "python",
   "name": "python38564bitvenvvenv3d0fdad24b0b4b62ac77901ca84c173f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
